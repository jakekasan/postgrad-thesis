
The panel data format has been of great interest to the field of econometrics in general. Adding the additional dimension opens the door for analysis and inference which may not be possible with the traditional single-dimension format. The effect of adding the cross section dimension to a panel is akin to increasing the sample size, meaning that inferences made on the basis of the sample parameters are more likely to resemble the population parameters \citep{smith}. An important property which a dataset needs for inferences to be valid is stationarity, and a long-standing issue with conventional stationarity tests is that they lack power for series which are short \citep{oh1996purchasing}. A proposed solution to this issue is to pool data in the form of panels and test the entire panel \citep{llc}. For econometrics at least, this has the advantage of allowing one to work with data in the time series format (as is the convention with most econometric analysis), while having increased data and power resulting from the inclusion of a cross-section \citep{baltagi2001nonstationary}. One of the main drivers in investigations into panel data stationarity is the analysis of economic growth and the disparity between different countries. The issues regarding the panel data stationarity test are two-fold: specification of the alternative hypothesis and dealing with cross sectional dependence. The first issue deals with whether the alternative hypothesis states that the entire panel is stationary or only a majority of it is stationary. The second issue deals with the phenomenon of having a panel which has correlations across the cross section. Over the last decade or two, there have been several very thorough surveys which have detailed the current state of panel data stationarity testing in light of the two issues mentioned earlier, for example the \citet{hurlin}, \cite{baltagi2001nonstationary} or \citet{hlouskova} to name a few. These papers have split the field of panel data stationarity tests into two generations: the first during which the alternative hypothesis (or indeed null hypothesis itself, in the case of \citet{hadri2000testing}) is formulated, and then the second generation, which attempts to deal with the presence of cross sectional dependence.

This paper examines and tests a real-world dataset provided by an industrial partner using selected panel unit root tests, and then performs Monte Carlo simulations on a controlled dataset which exposes the unit root tests to a controlled process in order to determine the conditions under which each test performs best, specifically the dimensions of the panels. The reason for the Monte Carlo simulations was to put context on the results obtained from the real world data. The Monte Carlo simulations were run 10,000 times on panels ranging from 8 observations of 2 individuals to 25 observations of 50 individuals, with the $\rho$ coefficient of 0.5, 0.75, 0.9 and 1. The cross section limit was intentionally larger than the time series limit due to the fact that this is an investigation into the benefits which arise from adding the cross section dimension to panels, for cases where the time series dimension is limited, as such a limitation was the original motivation for developing panel unit root tests \citep{hurlin}. The range for the $\rho$ coefficient was chosen in order to map the sensitivity of the tests to the degree of auto-regression, as well as the ability to distinguish a stationary process from one with a unit root.

Overall, this paper found that of the three tests considered, Levin-Lin-Chu, Maddala-Wu and Im-Pesaran-Shin, the Levin-Lin-Chu performed the best in terms of minimizing both type I and type II errors. The original (flawed) implementation of the Maddala-Wu tended heavily towards type II errors while the corrected version tended heavily towards type I errors. The Im-Pesaran-Shin performed erratically with small dimensions (initially moving further from the rejection region as T grew) but then converged at acceptance levels. The Im-Pesaran-Shin test also did not show a great deal of sensitivity to whether a process had a unit root or was very close to having a unit root, overall suggesting that either the implementation was flawed or the  Of the three tests, Levin-Lin-Chu was most likely to correctly distinguish between a unit root and a stationary process, especially as the time dimension moved beyond 16 observations, which is when the Levin-Lin-Chu would converge wholly in non-rejection territory (above 10\%). Maddala-Wu performed slightly worse, as it tended to give type 2 errors with a small sample size. Regardless, all three panel data tests performed better than the single-time series tests performed on the same data.

The rest of this paper is organised as follows: the Chapter 2 goes through the literature of panel data stationarity tests and establishes the current state of the field. The Chapter 3 deals with the raw real data, its structure and characteristics as well as those of the simulated data. The Chapter 4 details the methodology of this paper, including some of the coding conventions, as this was a major part in this investigation. The Chapter 5 details the results of both the real data tests as well as the findings of the Monte Carlo simulations, followed by an informed analysis and explanation which examines the results in light of the literature discussed in chapter two. Finally, Chapter 6 evaluates the work done and offers suggestions for further investigation.


