As discussed previously, the methodology is two-fold. The first part involves doing panel unit root tests on a combination of real-world time series, maximising T for every N while maintaining a balanced panel, and comparing the results of these tests with the individual stationarity tests, which will be done on the individuals of each panel. The reasoning behind this is that the panel data tests, with the enhanced cross-section, may offer a higher test power than the individual unit root tests. The second part of the methodology is a Monte Carlo simulation, which will be discussed in greater detail below. Due to errors in the way the Maddala-Wu test was implemented in the software package, additional steps were required to correctly apply it, which are detailed in the final section.

\section{Test Selection}

The choice of tests was limited by two factors. One was software availability; the entire methodology was performed in R, which had a fairly limited choice of panel unit root tests, namely Levin-Lin-Chu 2002, IPS 1997, Hadri 2000, and Maddala Wu 2000. Hadri was ruled out because the null hypothesis is stationarity, as opposed to a null of a unit root with the other three. The remaining tests, the Levin-Lin-Chu and Maddala-Wu, were acceptable due to the fact that the Levin-Lin-Chu is based on the Augmented Dickey-Fuller \citep{said1984testing} approach (therefore is comparable to the ADF test directly) while the Maddala-Wu is designed along the Fisher test principle, which essentially tests each time series in the panel individually, and then transforms the sum of the individual p-values into a test statistic which can be compared to a distribution. The second generation PANIC test was implemented in R, but as that largely depends on the correct specification of the common factors and their loadings, it was decided that the second generation tests would not be comparable to the other tests, and as the remit of this project is a comparison of the existing tests, the PANIC tests would not be included.

The second factor limiting test choice was time. It would take more time than was alloted for this work to create a comprehensive selection of both first-generation and second-generation tests, mostly because the software implementation of many of the panel tests does not exist (at least in the open-source realm, some tests such as the Breitung and Harris-Tzavalis are implemented in professional-grade statistics packages such as SAS) and therefore would have to be created from scratch. Additionally, the Monte Carlo simulations were time intensive to compute as it stood with 3 panel tests and 2 time series tests, therefore the addition of another 3 or so tests would have more than doubled the computation time, which was excessive as it was. Furthermore, the time element was also limited by the corrections required due to the errors with the Maddala-Wu test in the 'plm' package, as is discussed later. The decision to only use the Levin-Lin-Chu, Im-Pesaran-Shin and Maddala-Wu was therefore well justified.


For single time series unit root tests, the only real candidates were the Augmented Dickey-Fuller and the Phillips Perron. The KPSS test was considered initially, however the fact that the null and alternative hypotheses were different from the ADF and PP (KPSS has a null that the series is stationary vs. non-stationarity) meant that the KPSS was ruled out. ADF and PP have slightly different specification in that ADF is robust to deal with different AR and MA orders while PP is not, but this was not an issue, as the lag order was determined manually prior to using the tests, as was described in the data section. The ACF and PACF plots of each time series were examined and a decision was made to consider the data $AR(1)$.

The procedure for the Augmented Dickey Fuller was straightforward. Once the lag order was selected, the difference of the series (denoted as $\Delta y_t$) was regressed upon the lagged series (denoted as $y_{t-1}$) and the lagged difference of the series (denoted as $\Delta y_{t-1}$). The resulting critical value for the lagged series was compared with the Dickey-Fuller distribution based on the form of the DGP, which in this case was zero-mean, and if the critical value generated was less than the value given in the distribution, the null hypothesis was rejected in favour of the alternative, and the series is considered stationary.

The Phillips-Perron procedure is identical to the Augmented Dickey-Fuller test, except for the way that serial correlation is dealt with. While the ADF test adds the appropriate amount of lags to the final regression before the test statistic is generated, PP corrects the test statistic from the initial regression to correct for the presence of serial correlation.

The single time-series stationarity tests were sourced from the “tseries” package while the panel data stationarity tests were performed using the "plm" package, the full details and credits for both of these packages are given in the appendix. A few notes on the specification of the tests: the p-max variable, given in the tests to determine the maximum lag for which the significance should be tested, as described in $\cite{said1984testing}$, was set to 1 as this was determined to be the lag order when the data was being tested for auto-correlation. This also served to eliminate any advantage a particular test might have due to a superior lag-selection procedure. The exogenous variables were set to trend, as the data was identified as following a trend with intercept pattern in the data chapter (specifying 'trend' in the test function automatically added an intercept as well).

\section{Procedure}

The first step was to create panels from the individual time series. The panel sizes ranged from 39 observations of 2 individuals to 8 observations of 36 individuals. For each panel created, the two selected time series stationarity Augmented Dickey-Fuller and Phillips-Perron) tests were run on each individual time series, followed by the three selected panel data stationarity tests. The reason for this is to have direct comparability between the individual tests and the panel tests. The code for this is located in the appendices and discussed there in greater detail.

\section{Simulation}

For the simulation part of this investigation, panels were algorithmically generated in a range of predefined sizes, ranging from 2 to 50 for the individual dimension and 8 to 25 for the time dimension. The panels were comprised of autoregressive processing of order one (AR(1)), and the $\rho$ coefficient varied depending on the case being investigated. As stated in the data section, the coefficients for $\rho$ varied from 0.5, 0,75, 0.9, 1 where all but the last coefficient were stationary processes. The processes were all trend and intercept processes and can be expressed by:

\begin{equation}
y_t = \alpha + \beta t + \rho y_{t-1}
\end{equation}

Once each panel was generated, an ADF test and a PP test were performed on each individual in the panel, and the results were saved. Once this was completed, the panel unit root tests were performed, specifically the Levin-Lin-Chu and the Maddala-Wu. The procedures for both are described in more detail in the Literature Review section but will be mentioned here shortly. The LLC test performs the ADF on each individual and saves both sets of residuals, say $\bar{e}$ and $\bar{f}$. $\bar{e}$ is then regressed on $\bar{f}$, and the standard error from this regression is used to standardize $\bar{e}$ and $\bar{f}$ into $\hat{e}$ and $\hat{f}$. Following this, both long-run and short-run variance is calculated and then the test statistic is calculated using the formula mentioned in 2.3.1 under "Levin et al 2002." This statistic is then compared to the correct distribution, which is normal for zero-mean cases and has to be normalized for either an intercept or trend case.


The Maddala-Wu is by comparison much more straightforward: each individual time series undergoes an individual unit root test, which can be any test desired (in the "plm" package the chosen test is the Augmented Dickey-Fuller), and the p-values of these tests are saved. The p-values are then passed through the formula mentioned in 2.3.1 to generate a test statistic which follows a chi-squared distribution with 2*N degrees of freedom. 

The Im-Pesaran-Shin is very similar to the Maddala-Wu test in that it is averaging the results from individual tests. Unlike the Maddala-Wu, however, the Im-Pesaran-Shin test takes the critical value generated from the Dickey-Fuller regression and averages it, generating a test statistic which is then standardized and is normally distributed as $T \to \inf$ and $N \to \inf$.

\subsection{Software}

Because each process in each panel had a stochastic element (the error term) the simulation was a Monte Carlo simulation with 10,000 iterations for each dimension, and for each iteration the individual tests would be done on the individuals, followed by the panel data test, but the underlying panel data would not change during the iteration.

In terms of software, while this will be discussed somewhat in the appendix, it should be noted that this investigation relied heavily upon pre-programmed libraries available for R, as the time frame was too short to develop bespoke and robust testing procedures. The libraries which were used were “plm” and “tseries” for the tests, as well as the “parallels” and “foreach” libraries”, each of which had their own dependacies which are listed fully in the appendix. “Parallels” and “foreach” were used for their parallel computation, as the Monte Carlo simulations were extremely computation-intensive, requiring over 8 billion instances were a panel was created and tested. The details of these packages is included in the appendix.

\section{Maddala-Wu Implementation}

The implementation of the Maddala-Wu panel test in the "plm" library uses the Augmented Dickey-Fuller test as the individual test, from which the p-values are then sourced. The issue with the implementation is that after the critical values are calculated, they are then compared to a normal distribution to determine the p-values. As is known, the critical value in the Dickey-Fuller test must be compared to a bespoke Dickey-Fuller distribution, which will depend on the case (zero-mean, intercept, or trend) and the length of the series. The way that this issue was overcome was that the Dickey-Fuller distributions were created using Monte-Carlo simulations, and the critical values were generated from a bespoke Augmented Dickey-Fuller test and compared to the custom distributions. The code for steps described is located in the appendix.




